{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0122f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "#import ipython_genutils\n",
    "\n",
    "class read_sql:\n",
    "    \"\"\"\n",
    "    Read the SQL output of energyplus file, it's able to extract output variables reported by energyplus simulation or construction systems of the model\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    file -- path location of SQL file\n",
    "    read -- mode of reading, initial options: \"all\" and \"constructions\"\n",
    "    cols_json -- json file to rename the columns\n",
    "    \n",
    "    Properties:\n",
    "    data -- pandas dataframe with data extracted of SQL file\n",
    "    variables -- name of variables using energyplus notation\n",
    "    vars -- ??\n",
    "    vars_numbered -- ??\n",
    "    mlc -- ??\n",
    "    construction_systems -- Construction Systems found inside SQL file\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,file,read=\"all\",cols_json=None):\n",
    "        \"\"\"\n",
    "        Read the SQL output of energyplus file\n",
    "        \"\"\"\n",
    "        self.myconn = sql.connect(file)\n",
    "        if (read==\"data\") or (read==\"all\"):\n",
    "            command = \"SELECT ReportDataDictionaryIndex, KeyValue, Name, Units FROM ReportDataDictionary\"\n",
    "            variables = pd.read_sql_query(command,con=self.myconn)\n",
    "\n",
    "            variables['variable_name'] = variables.KeyValue + ':' + variables.Name + ' (' + variables.Units + ')'\n",
    "            self.variables = variables\n",
    "            \n",
    "            self.vars = variables.variable_name.unique()\n",
    "            vars = variables.variable_name.unique()\n",
    "            self.vars_numbered = [i for i in enumerate(self.vars)]\n",
    "            \n",
    "            command = \"SELECT tm.TimeIndex, tm.Year, tm.Month, tm.Day, tm.Hour, tm.Minute FROM Time AS tm\"\n",
    "            time = pd.read_sql_query(command,con=self.myconn)\n",
    "            time = time[time.Year!=0]\n",
    "            command = \"\"\"SELECT ReportData.TimeIndex, ReportData.ReportDataDictionaryIndex, ReportData.Value\n",
    "              FROM (ReportData INNER JOIN ReportDataDictionary ON ReportData.ReportDataDictionaryIndex = ReportDataDictionary.ReportDataDictionaryIndex) \n",
    "              INNER JOIN Time ON ReportData.TimeIndex = Time.TimeIndex\"\"\"\n",
    "            data = pd.read_sql_query(command,con=self.myconn)\n",
    "            data_variables = pd.merge(data,self.variables)\n",
    "            data_variables_time = pd.merge(data_variables,time)\n",
    "            df = data_variables_time.copy()\n",
    "            df['date'] = pd.to_datetime(df[['Year','Month','Day']])\n",
    "            df.loc[df.Hour==24,'date'] += pd.Timedelta('1D')\n",
    "            df.loc[df.Hour==24,'Hour'] = 0\n",
    "            df['date'] = pd.to_datetime(df[['Year','Month','Day','Hour','Minute']])\n",
    "            df['variable_name'] = df.KeyValue + ':' + df.Name + ' (' + df.Units + ')'\n",
    "            df  = df.pivot_table(index=\"date\", columns=\"variable_name\", values=\"Value\")\n",
    "            \n",
    "            # If json doesn't exists, extract all output variables, else create dataframe only with output variables inside dictionary\n",
    "            if cols_json == None:\n",
    "                self.data = df\n",
    "            else:\n",
    "                self.data = pd.DataFrame()\n",
    "                for col_name in df.columns:\n",
    "                    for key in cols_json.keys():\n",
    "                        if key in col_name:\n",
    "                            self.data[cols_json[key]] = df[col_name]\n",
    "                            break\n",
    "                if \"date\" in cols_json.keys():\n",
    "                    self.data.index.names = [cols_json[\"date\"]]\n",
    "        \n",
    "        if (read==\"construction\") or (read==\"all\"):\n",
    "#             print(\"aca\")\n",
    "            command = \"\"\"SELECT * FROM  Materials \"\"\"\n",
    "            m       = pd.read_sql_query(command,con=self.myconn)\n",
    "            m = m.rename(columns={'Name': 'NameMaterial'})\n",
    "            # \n",
    "            command = \"\"\"SELECT * FROM  Constructions \"\"\"\n",
    "            c = pd.read_sql_query(command,con=self.myconn)\n",
    "            c = c.rename(columns={'Name': 'NameConstruction'})\n",
    "            # \n",
    "            command = \"\"\"SELECT * FROM  ConstructionLayers \"\"\"\n",
    "            l = pd.read_sql_query(command,con=self.myconn)\n",
    "            ml   = pd.merge(m,l)\n",
    "            mlc = pd.merge(ml,c)\n",
    "            self.mlc = mlc\n",
    "            self.construction_systems = mlc.NameConstruction.unique()\n",
    "        self.myconn.close()\n",
    "    @classmethod\n",
    "    def json_from_rvi(cls, file_path, use_gee_names = True):\n",
    "        # If the file has not finished with \"rvi\", it will launch an error\n",
    "        assert file_path[-3:] == \"rvi\" , \"The extension of file must be 'rvi'\"\n",
    "        # Open file and save lines in rvi\n",
    "        with open(file_path) as file:\n",
    "            rvi = file.readlines()\n",
    "        # Dispose two first lines, and last one.\n",
    "        rvi = rvi = rvi[2:-1]\n",
    "        cols_json = {}\n",
    "        for var in rvi:\n",
    "            var_name = var.split('\\n')[0].replace(',', ':')\n",
    "            cols_json[var_name] = var_name\n",
    "        if (use_gee_names):\n",
    "            read_sql.__rename(cols_json)\n",
    "        return cols_json\n",
    "\n",
    "    def rename_from_sql(self):\n",
    "        variables = self.vars\n",
    "        cols_json = {}\n",
    "        for variable in variables:\n",
    "            cols_json.update({variable:variable})\n",
    "        read_sql.__rename(cols_json)\n",
    "#         self.vars = self.data.columns\n",
    "#         print(self.vars)\n",
    "        return cols_json\n",
    "    def rename(self,columns,inplace=True):\n",
    "        self.data.rename(columns=columns,inplace=True)\n",
    "        self.vars = self.data.columns\n",
    "        self.vars_numbered = [i for i in enumerate(self.vars)]\n",
    "    def __rename(cols_json):\n",
    "        variables  = cols_json.keys()\n",
    "        for variable in variables:\n",
    "            if \"Zone Mean Air Temperature\" in variable:\n",
    "                Ti_variables = \"Ti_\" + variable.split(\":\")[0].replace(\" \",\"\")\n",
    "                cols_json[variable] = Ti_variables\n",
    "            if \"Site Outdoor Air Dry\" in variable:\n",
    "                cols_json[variable] = \"To\"\n",
    "            if \"Wind Speed\" in variable:\n",
    "                cols_json[variable] = \"ws\"\n",
    "            if \"Wind Direction\" in variable:\n",
    "                cols_json[variable] = \"wd\"\n",
    "            if \"Site Outdoor Air Relative Humidity\" in variable:\n",
    "                cols_json[variable] = \"hr\"\n",
    "            if \"Environment:Site Diffuse Solar Radiation Rate\" in variable:\n",
    "                cols_json[variable] = \"Id\"\n",
    "            if \"Environment:Site Direct Solar Radiation Rate\" in variable:\n",
    "                cols_json[variable] = \"Ib\"\n",
    "#         return cols_json\n",
    "    def rename_cols(self,columns,new_names):\n",
    "        old_names = self.data.columns[columns]\n",
    "        self.data.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "        self.vars = self.data.columns\n",
    "        self.vars_numbered = [i for i in enumerate(self.vars)]\n",
    "    def rename_from_json(self,file_path):\n",
    "        ''' To be developed'''\n",
    "        pass\n",
    "    def to_json(self,diccionario,json_path):\n",
    "        '''To be developed'''\n",
    "        pass\n",
    "#     @property\n",
    "#     def data(self):\n",
    "#         \"\"\"\n",
    "#         Dataframe with output variables\n",
    "#         \"\"\"  \n",
    "#         return self._data\n",
    "\n",
    "    def get_data(self, names):\n",
    "        result = [variable for name in names for variable in self.vars if name in variable]\n",
    "        return self.data[result]\n",
    "\n",
    "    def get_construction(self,names_cs,round=4):\n",
    "#         all = []\n",
    "        for name_cs in names_cs:\n",
    "            properties = ['NameMaterial','Conductivity', 'Density','SpecHeat', 'Thickness', \n",
    "                          'TotalLayers', 'InsideAbsorpVis', 'OutsideAbsorpVis','InsideAbsorpSolar',\n",
    "                          'OutsideAbsorpSolar', 'InsideAbsorpThermal',\n",
    "                          'OutsideAbsorpThermal', 'OutsideRoughness']\n",
    "            cs = self.mlc.loc[self.mlc.NameConstruction==name_cs].sort_values('ConstructionLayersIndex')[properties]\n",
    "            thickness =  cs['Thickness'].sum().round(round)\n",
    "            total_layers = cs.TotalLayers.unique()\n",
    "            InsideAbsopVis = cs.InsideAbsorpVis.unique()\n",
    "            OutsideAbsopVis = cs.OutsideAbsorpVis.unique()\n",
    "            OutsideAbsorpSolar = cs.OutsideAbsorpSolar.unique()\n",
    "            InsideAbsorpThermal = cs.InsideAbsorpThermal.unique()\n",
    "            OutsideAbsorpThermal = cs.OutsideAbsorpThermal.unique()\n",
    "            OutsideRoughness = cs.OutsideRoughness.unique()\n",
    "#             dictio = {'Construction system':name_cs,\n",
    "#                       'Total thickness':thickness,\n",
    "#                       'Total layers':total_layers,\n",
    "#                       'InsideAbsorpVis':InsideAbsopVis,\n",
    "#                       \"OutsideAbsorpVis\":OutsideAbsopVis,\n",
    "#                       \"OutsideAbsorpSolar\":OutsideAbsorpSolar,\n",
    "#                       \"InsideAbsorpThermal\":InsideAbsorpThermal,\n",
    "#                       \"OutsideRoughness\":OutsideRoughness\n",
    "#                      }\n",
    "            print('\\n')\n",
    "            print(f'Construction system:\\033[1m{name_cs}\\033[0m')\n",
    "            print(f'Total thickness    :{thickness} m')\n",
    "            print(f'Total layers:{total_layers}')\n",
    "            print(f\"InsideAbsorpVis:{InsideAbsopVis}\")\n",
    "            print(f\"OutsideAbsorpVis:{OutsideAbsopVis}\")\n",
    "            print(f\"OutsideAbsorpSolar:{OutsideAbsorpSolar}\")\n",
    "            print(f\"InsideAbsorpThermal:{InsideAbsorpThermal}\")\n",
    "            print(f\"OutsideRoughness:{OutsideRoughness}\")\n",
    "            properties = ['NameMaterial','Conductivity', 'Density','SpecHeat', 'Thickness']\n",
    "            display(cs[properties].style.hide_index())\n",
    "            print('\\n\\n\\n')\n",
    "#         return all\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
